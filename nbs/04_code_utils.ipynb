{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code_utils\n",
    "\n",
    "> Stata-related helper functions with no Jupyter or pystata dependence\n",
    "- order: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are mostly intended for use in the `noecho` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp code_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pygments import lexers\n",
    "from pygments.token import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Stata comments and `#delimit;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Detect comments spanning multiple lines\n",
    "comment_regex = re.compile(r'(((?: |\\t)\\/\\/\\/)(.)*(\\n|\\r)|(\\/\\*)(.|\\s)*?(\\*\\/))')\n",
    "\n",
    "def _remove_multi_line_comments(code):\n",
    "    return comment_regex.sub(' ',code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/main/nbstata/code_utils.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _remove_multi_line_comments\n",
       "\n",
       ">      _remove_multi_line_comments (code)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/main/nbstata/code_utils.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _remove_multi_line_comments\n",
       "\n",
       ">      _remove_multi_line_comments (code)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(_remove_multi_line_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    _remove_multi_line_comments(dedent(\"\"\"\\\n",
    "        disp ///\n",
    "        1\"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly ignores \"///\" when not preceded by a space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    _remove_multi_line_comments(dedent(\"\"\"\\\n",
    "        disp///\n",
    "        1\n",
    "        \"\"\")),\n",
    "    dedent(\"\"\"\\\n",
    "        disp///\n",
    "        1\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    _remove_multi_line_comments(dedent(\"\"\"\\\n",
    "        /*\n",
    "        blah\n",
    "        blah\n",
    "        */\n",
    "        list var\n",
    "        \"\"\")),\n",
    "    \"\"\"\\\n",
    " \n",
    "list var\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "stata_lexer = lexers.get_lexer_by_name('stata')\n",
    "\n",
    "def _lex_tokens(code):\n",
    "    return stata_lexer.get_tokens_unprocessed(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "* [https://pygments.org/docs/api/#pygments.lexer.Lexer.get_tokens_unprocessed](https://pygments.org/docs/api/#pygments.lexer.Lexer.get_tokens_unprocessed)\n",
    "* [https://github.com/pygments/pygments/blob/master/pygments/lexers/stata.py](https://github.com/pygments/pygments/blob/master/pygments/lexers/stata.py)\n",
    "* [https://github.com/pygments/pygments/blob/master/pygments/token.py](https://github.com/pygments/pygments/blob/master/pygments/token.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_comments(code):\n",
    "    return \"\".join(token[2] for token in _lex_tokens(code) if token[1] not in Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Token.Keyword, 'tab'),\n",
       " (3, Token.Text, ' '),\n",
       " (4, Token.Text, 's'),\n",
       " (5, Token.Text, 'i'),\n",
       " (6, Token.Text, 'z'),\n",
       " (7, Token.Text, 'e'),\n",
       " (8, Token.Keyword, ' if'),\n",
       " (11, Token.Text, ' '),\n",
       " (12, Token.Name.Function, 'inlist'),\n",
       " (18, Token.Text, '('),\n",
       " (19, Token.Text, 'r'),\n",
       " (20, Token.Text, 't'),\n",
       " (21, Token.Text, '_'),\n",
       " (22, Token.Text, 'f'),\n",
       " (23, Token.Text, 'r'),\n",
       " (24, Token.Text, 'o'),\n",
       " (25, Token.Text, 'm'),\n",
       " (26, Token.Text, '_'),\n",
       " (27, Token.Text, 't'),\n",
       " (28, Token.Text, 'o'),\n",
       " (29, Token.Text, ','),\n",
       " (30, Token.Text, ' '),\n",
       " (31, Token.Literal.String, '\"'),\n",
       " (32, Token.Literal.String, 'A'),\n",
       " (33, Token.Literal.String, '1'),\n",
       " (34, Token.Literal.String, '0'),\n",
       " (35, Token.Literal.String, 'T'),\n",
       " (36, Token.Literal.String, 'O'),\n",
       " (37, Token.Literal.String, 'U'),\n",
       " (38, Token.Literal.String, ' '),\n",
       " (39, Token.Literal.String, 't'),\n",
       " (40, Token.Literal.String, 'o'),\n",
       " (41, Token.Literal.String, ' '),\n",
       " (42, Token.Literal.String, 'B'),\n",
       " (43, Token.Literal.String, '1'),\n",
       " (44, Token.Literal.String, '0'),\n",
       " (45, Token.Literal.String, '\"'),\n",
       " (46, Token.Text, ','),\n",
       " (47, Token.Text, ' '),\n",
       " (48, Token.Literal.String, '\"'),\n",
       " (49, Token.Literal.String, 'E'),\n",
       " (50, Token.Literal.String, '1'),\n",
       " (51, Token.Literal.String, '9'),\n",
       " (52, Token.Literal.String, ' '),\n",
       " (53, Token.Literal.String, 't'),\n",
       " (54, Token.Literal.String, 'o'),\n",
       " (55, Token.Literal.String, ' '),\n",
       " (56, Token.Literal.String, 'B'),\n",
       " (57, Token.Literal.String, '1'),\n",
       " (58, Token.Literal.String, '9'),\n",
       " (59, Token.Literal.String, '\"'),\n",
       " (60, Token.Text, ','),\n",
       " (61, Token.Text, ' '),\n",
       " (62, Token.Literal.String, '\"'),\n",
       " (63, Token.Literal.String, 'A'),\n",
       " (64, Token.Literal.String, 'G'),\n",
       " (65, Token.Literal.String, '4'),\n",
       " (66, Token.Literal.String, 'B'),\n",
       " (67, Token.Literal.String, ' '),\n",
       " (68, Token.Literal.String, 't'),\n",
       " (69, Token.Literal.String, 'o'),\n",
       " (70, Token.Literal.String, ' '),\n",
       " (71, Token.Literal.String, 'A'),\n",
       " (72, Token.Literal.String, 'G'),\n",
       " (73, Token.Literal.String, 'B'),\n",
       " (74, Token.Literal.String, '\"'),\n",
       " (75, Token.Text, ','),\n",
       " (76, Token.Text, ' '),\n",
       " (77, Token.Literal.String, '\"'),\n",
       " (78, Token.Literal.String, 'A'),\n",
       " (79, Token.Literal.String, 'G'),\n",
       " (80, Token.Literal.String, '5'),\n",
       " (81, Token.Literal.String, 'B'),\n",
       " (82, Token.Literal.String, ' '),\n",
       " (83, Token.Literal.String, 't'),\n",
       " (84, Token.Literal.String, 'o'),\n",
       " (85, Token.Literal.String, ' '),\n",
       " (86, Token.Literal.String, 'A'),\n",
       " (87, Token.Literal.String, 'G'),\n",
       " (88, Token.Literal.String, 'C'),\n",
       " (89, Token.Literal.String, '\"'),\n",
       " (90, Token.Text, ')'),\n",
       " (91, Token.Text, ' '),\n",
       " (92, Token.Text, ' '),\n",
       " (93, Token.Comment.Single, '//'),\n",
       " (95, Token.Comment.Single, '\"'),\n",
       " (96, Token.Comment.Single, 'E'),\n",
       " (97, Token.Comment.Single, '2'),\n",
       " (98, Token.Comment.Single, '0'),\n",
       " (99, Token.Comment.Single, ' '),\n",
       " (100, Token.Comment.Single, 't'),\n",
       " (101, Token.Comment.Single, 'o'),\n",
       " (102, Token.Comment.Single, ' '),\n",
       " (103, Token.Comment.Single, 'B'),\n",
       " (104, Token.Comment.Single, '2'),\n",
       " (105, Token.Comment.Single, '0'),\n",
       " (106, Token.Comment.Single, '\"'),\n",
       " (107, Token.Comment.Single, ','),\n",
       " (108, Token.Comment.Single, ' '),\n",
       " (109, Token.Comment.Single, '\"'),\n",
       " (110, Token.Comment.Single, ','),\n",
       " (111, Token.Comment.Single, ' '),\n",
       " (112, Token.Comment.Single, 's'),\n",
       " (113, Token.Comment.Single, 'o'),\n",
       " (114, Token.Comment.Single, 'r'),\n",
       " (115, Token.Comment.Single, 't')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(_lex_tokens('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\", \"AG4B to AGB\", \"AG5B to AGC\")  //\"E20 to B20\", \", sort'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  //\"E20 to B20\", \", sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(remove_comments('*tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  //\"E20 to B20\", \", sort'), \n",
    "        '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  /*\"E20 to B20\", \", sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  /*\"E20 to B20\", \"*/, sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  , sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  ///\"E20 to B20\", \"*/ \\n , sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")   , sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _is_cr_delimiter(delimiter):\n",
    "    return delimiter in {'cr', None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "delimit_regex = re.compile(r'#delimit(.*$)', flags=re.MULTILINE)\n",
    "def _replace_delimiter(code, sc_delimiter=False):\n",
    "    # Recursively replace custom delimiter with newline\n",
    "\n",
    "    split = delimit_regex.split(code.strip(),maxsplit=1)\n",
    "\n",
    "    if len(split) == 3:\n",
    "        before = split[0]\n",
    "        after = _replace_delimiter(split[2],not _is_cr_delimiter(split[1].strip()))\n",
    "    else:\n",
    "        before = code\n",
    "        after = ''\n",
    "\n",
    "    if sc_delimiter:\n",
    "        before = before.replace('\\r', ' ').replace('\\n', ' ')\n",
    "        before = before.replace(';','\\n')\n",
    "\n",
    "    return before + after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/main/nbstata/code_utils.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _replace_delimiter\n",
       "\n",
       ">      _replace_delimiter (code, sc_delimiter=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/main/nbstata/code_utils.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _replace_delimiter\n",
       "\n",
       ">      _replace_delimiter (code, sc_delimiter=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(_replace_delimiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following more-complicated regex would detect valid delimiters plus macros: \n",
    "```python\n",
    "delimit_regex = re.compile(r'#delimit( |\\t)+(;|cr|`.+\\'|\\$_.+|\\$.+)')\n",
    "```\n",
    "but that's unnecessary, since Stata's `#delimit x` interprets any `x` other than 'cr' as switching the delimiter to ';'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    _replace_delimiter(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2;list var3;\n",
    "        list\n",
    "        var4;\n",
    "        \"\"\")),\n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "         list var2\n",
    "        list var3\n",
    "         list var4\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_replace_delimiter(dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    #delimit;\n",
    "    disp \"hello\"; disp \"hello2\";\n",
    "    disp \n",
    "        \"hello2a\";\n",
    "    #delimit cr\n",
    "    disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    #delimit;\"\"\")), \n",
    "        dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    disp \"hello\"\n",
    "     disp \"hello2\"\n",
    "     disp      \"hello2a\"\n",
    "     disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ending_sc_delimiter(code, sc_delimiter=False):\n",
    "    code = _remove_multi_line_comments(code)\n",
    "    # Recursively determine ending delimiter\n",
    "    split = delimit_regex.split(code.strip(),maxsplit=1)\n",
    "    if len(split) == 3:\n",
    "        sc_delimiter = ending_sc_delimiter(split[2], not _is_cr_delimiter(split[1].strip()))\n",
    "    elif len(split) == 2:\n",
    "        sc_delimiter = not _is_cr_delimiter(split[1].strip())\n",
    "    return sc_delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2;list var3;\n",
    "        \"\"\")),\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        /*\n",
    "        #delimit;\n",
    "        */\n",
    "        disp 1\n",
    "        disp 2\"\"\")),\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        #delimit;\n",
    "        scalar\n",
    "        list x\"\"\")),\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Detect Multiple whitespace\n",
    "multi_regex = re.compile(r' +')\n",
    "\n",
    "def standardize_code(code, sc_delimiter=False):\n",
    "    \"\"\"Remove comments spanning multiple lines and replace custom delimiters\"\"\"\n",
    "    code = _remove_multi_line_comments(code)\n",
    "    \n",
    "    # After removing multi-line comments, which could include \"#delimit;\"\n",
    "    code = _replace_delimiter(code, sc_delimiter) \n",
    "    \n",
    "    # Replace multiple whitespace with one\n",
    "    code = multi_regex.sub(' ',code)\n",
    "    \n",
    "    # Delete blank lines and whitespace at start and end of lines\n",
    "    code_lines = code.splitlines()\n",
    "    std_lines = []\n",
    "    for code_line in code_lines:\n",
    "        cs = code_line.strip()\n",
    "        if cs:\n",
    "            std_lines.append(cs)\n",
    "    return '\\n'.join(std_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2; list var3;\n",
    "        list\n",
    "        var4;\n",
    "        \"\"\")), \n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "        list var2\n",
    "        list var3\n",
    "        list var4\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        /*\n",
    "        blah\n",
    "        blah\n",
    "        */\n",
    "        list var\n",
    "        \"\"\")), \n",
    "    \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        /*\n",
    "        #delimit;\n",
    "        */\n",
    "        disp 1\n",
    "        disp 2\n",
    "        \"\"\")), \n",
    "    dedent(\"\"\"\\\n",
    "        disp 1\n",
    "        disp 2\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        disp ///\n",
    "        1\n",
    "        \"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        disp /// comment\n",
    "        1\n",
    "        \"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        list var\n",
    "        \"\"\")), \n",
    "    \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(standardize_code(\"list    var\"), \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display \"displayed1\"\\ndisplay \"displayed3\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_code('''\\\n",
    "display \"displayed1\"\n",
    "/*\n",
    "display \"displayed2\"\n",
    "*/\n",
    "display \"displayed3\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display \"line continuation \" \"comment\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "standardize_code('''\\\n",
    "display \"line continuation \" /// commented out\n",
    "    \"comment\"''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate out Stata program code\n",
    "...because [such code](https://www.stata.com/manuals/pprogram.pdf) (as well as [python](https://www.stata.com/stata-news/news35-3/python-blogs/)/[mata](https://www.stata.com/manuals/m-1first.pdf) blocks) is unsuitable for `run_as_program`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _startswith_stata_abbrev(string, full_command, shortest_abbrev):\n",
    "    for j in range(len(shortest_abbrev), len(full_command)+1):\n",
    "        if string.startswith(full_command[0:j] + ' '):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_startswith_stata_abbrev(\"q list var\", \"quietly\", \"q\"), True)\n",
    "test_eq(_startswith_stata_abbrev(\"qui list var\", \"quietly\", \"q\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _remove_prog_prefixes(cs):\n",
    "    if (_startswith_stata_abbrev(cs, 'quietly', 'qui')\n",
    "        or cs.startswith('capture ')\n",
    "        or _startswith_stata_abbrev(cs, 'noisily', 'n')):\n",
    "        return _remove_prog_prefixes(cs.split(None, maxsplit=1)[1])\n",
    "    else:\n",
    "        return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_remove_prog_prefixes(\"capture noisily program test_program\"), \"program test_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_start_of_program_block(std_code_line):\n",
    "    cs = _remove_prog_prefixes(std_code_line)\n",
    "    _starts_program = (_startswith_stata_abbrev(cs, 'program', 'pr')\n",
    "                       and not (cs.split()[1] in ['di', 'dir', 'drop', 'l', 'li', 'lis', 'list']))\n",
    "    return (_starts_program\n",
    "            or (cs in {'mata', 'mata:'})\n",
    "            or (cs in {'python', 'python:'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(is_start_of_program_block(\"capture noisily program test_program\"), True)\n",
    "test_eq(is_start_of_program_block(\"capture noisily list var\"), False)\n",
    "test_eq(is_start_of_program_block(\"pr l display1\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _prog_blocks(std_code_lines):\n",
    "    next_block_lines = []\n",
    "    in_program = False\n",
    "    for std_code_line in std_code_lines:         \n",
    "        if is_start_of_program_block(std_code_line):\n",
    "            if next_block_lines: # previous lines\n",
    "                yield _block(next_block_lines, is_prog=in_program)\n",
    "                next_block_lines = []\n",
    "            in_program = True\n",
    "        next_block_lines.append(std_code_line)\n",
    "        if std_code_line == 'end': # regardless of whether in_program\n",
    "            yield _block(next_block_lines, is_prog=True)\n",
    "            next_block_lines = []\n",
    "            in_program = False\n",
    "    if next_block_lines:\n",
    "        yield _block(next_block_lines, in_program)\n",
    "        \n",
    "\n",
    "def _block(block_lines, is_prog):\n",
    "    return {\"is_prog\": is_prog, \"std_code\": '\\n'.join(block_lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def break_out_prog_blocks(code, sc_delimiter=False):\n",
    "    std_code_lines = standardize_code(code, sc_delimiter).splitlines()\n",
    "    return list(_prog_blocks(std_code_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    break_out_prog_blocks(dedent('''\\\n",
    "        capture program drop ender\n",
    "        program define ender\n",
    "            disp \"ender output\"\n",
    "        end\n",
    "        capture program drop display2\n",
    "        program define display2\n",
    "            ender\n",
    "        end\n",
    "        display2\n",
    "        ''')),\n",
    "    [{'is_prog': False, 'std_code': 'capture program drop ender'},\n",
    "     {'is_prog': True,\n",
    "      'std_code': 'program define ender\\ndisp \"ender output\"\\nend'},\n",
    "     {'is_prog': False, 'std_code': 'capture program drop display2'},\n",
    "     {'is_prog': True, 'std_code': 'program define display2\\nender\\nend'},\n",
    "     {'is_prog': False, 'std_code': 'display2'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    break_out_prog_blocks(dedent('''\\\n",
    "        program define ender\n",
    "            disp \"ender output\"\n",
    "        ''')),\n",
    "    [{'is_prog': True,\n",
    "      'std_code': 'program define ender\\ndisp \"ender output\"'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_prog': False, 'std_code': 'display \"line continuation \" \"comment\"'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "break_out_prog_blocks('''\\\n",
    "display \"line continuation \" /// commented out\n",
    "    \"comment\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
