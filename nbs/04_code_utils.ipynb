{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code_utils\n",
    "\n",
    "> Stata-related helper functions with no Jupyter or pystata dependence\n",
    "- order: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are mostly intended for use in the `noecho` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp code_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pygments import lexers\n",
    "from pygments.token import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, ExceptionExpected\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Stata comments and `#delimit;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "stata_lexer = lexers.get_lexer_by_name('stata')\n",
    "\n",
    "def _lex_tokens(code):\n",
    "    return stata_lexer.get_tokens_unprocessed(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "* [https://pygments.org/docs/api/#pygments.lexer.Lexer.get_tokens_unprocessed](https://pygments.org/docs/api/#pygments.lexer.Lexer.get_tokens_unprocessed)\n",
    "* [https://github.com/pygments/pygments/blob/master/pygments/lexers/stata.py](https://github.com/pygments/pygments/blob/master/pygments/lexers/stata.py)\n",
    "* [https://github.com/pygments/pygments/blob/master/pygments/token.py](https://github.com/pygments/pygments/blob/master/pygments/token.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_comments(code):\n",
    "    return \"\".join(token[2] for token in _lex_tokens(code) if token[1] not in Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Token.Keyword, 'tab'),\n",
       " (3, Token.Text, ' '),\n",
       " (4, Token.Text, 's'),\n",
       " (5, Token.Text, 'i'),\n",
       " (6, Token.Text, 'z'),\n",
       " (7, Token.Text, 'e'),\n",
       " (8, Token.Keyword, ' if'),\n",
       " (11, Token.Text, ' '),\n",
       " (12, Token.Name.Function, 'inlist'),\n",
       " (18, Token.Text, '('),\n",
       " (19, Token.Text, 'r'),\n",
       " (20, Token.Text, 't'),\n",
       " (21, Token.Text, '_'),\n",
       " (22, Token.Text, 'f'),\n",
       " (23, Token.Text, 'r'),\n",
       " (24, Token.Text, 'o'),\n",
       " (25, Token.Text, 'm'),\n",
       " (26, Token.Text, '_'),\n",
       " (27, Token.Text, 't'),\n",
       " (28, Token.Text, 'o'),\n",
       " (29, Token.Text, ','),\n",
       " (30, Token.Text, ' '),\n",
       " (31, Token.Literal.String, '\"'),\n",
       " (32, Token.Literal.String, 'A'),\n",
       " (33, Token.Literal.String, '1'),\n",
       " (34, Token.Literal.String, '0'),\n",
       " (35, Token.Literal.String, 'T'),\n",
       " (36, Token.Literal.String, 'O'),\n",
       " (37, Token.Literal.String, 'U'),\n",
       " (38, Token.Literal.String, ' '),\n",
       " (39, Token.Literal.String, 't'),\n",
       " (40, Token.Literal.String, 'o'),\n",
       " (41, Token.Literal.String, ' '),\n",
       " (42, Token.Literal.String, 'B'),\n",
       " (43, Token.Literal.String, '1'),\n",
       " (44, Token.Literal.String, '0'),\n",
       " (45, Token.Literal.String, '\"'),\n",
       " (46, Token.Text, ','),\n",
       " (47, Token.Text, ' '),\n",
       " (48, Token.Literal.String, '\"'),\n",
       " (49, Token.Literal.String, 'E'),\n",
       " (50, Token.Literal.String, '1'),\n",
       " (51, Token.Literal.String, '9'),\n",
       " (52, Token.Literal.String, ' '),\n",
       " (53, Token.Literal.String, 't'),\n",
       " (54, Token.Literal.String, 'o'),\n",
       " (55, Token.Literal.String, ' '),\n",
       " (56, Token.Literal.String, 'B'),\n",
       " (57, Token.Literal.String, '1'),\n",
       " (58, Token.Literal.String, '9'),\n",
       " (59, Token.Literal.String, '\"'),\n",
       " (60, Token.Text, ','),\n",
       " (61, Token.Text, ' '),\n",
       " (62, Token.Literal.String, '\"'),\n",
       " (63, Token.Literal.String, 'A'),\n",
       " (64, Token.Literal.String, 'G'),\n",
       " (65, Token.Literal.String, '4'),\n",
       " (66, Token.Literal.String, 'B'),\n",
       " (67, Token.Literal.String, ' '),\n",
       " (68, Token.Literal.String, 't'),\n",
       " (69, Token.Literal.String, 'o'),\n",
       " (70, Token.Literal.String, ' '),\n",
       " (71, Token.Literal.String, 'A'),\n",
       " (72, Token.Literal.String, 'G'),\n",
       " (73, Token.Literal.String, 'B'),\n",
       " (74, Token.Literal.String, '\"'),\n",
       " (75, Token.Text, ','),\n",
       " (76, Token.Text, ' '),\n",
       " (77, Token.Literal.String, '\"'),\n",
       " (78, Token.Literal.String, 'A'),\n",
       " (79, Token.Literal.String, 'G'),\n",
       " (80, Token.Literal.String, '5'),\n",
       " (81, Token.Literal.String, 'B'),\n",
       " (82, Token.Literal.String, ' '),\n",
       " (83, Token.Literal.String, 't'),\n",
       " (84, Token.Literal.String, 'o'),\n",
       " (85, Token.Literal.String, ' '),\n",
       " (86, Token.Literal.String, 'A'),\n",
       " (87, Token.Literal.String, 'G'),\n",
       " (88, Token.Literal.String, 'C'),\n",
       " (89, Token.Literal.String, '\"'),\n",
       " (90, Token.Text, ')'),\n",
       " (91, Token.Text, ' '),\n",
       " (92, Token.Text, ' '),\n",
       " (93, Token.Comment.Single, '//'),\n",
       " (95, Token.Comment.Single, '\"'),\n",
       " (96, Token.Comment.Single, 'E'),\n",
       " (97, Token.Comment.Single, '2'),\n",
       " (98, Token.Comment.Single, '0'),\n",
       " (99, Token.Comment.Single, ' '),\n",
       " (100, Token.Comment.Single, 't'),\n",
       " (101, Token.Comment.Single, 'o'),\n",
       " (102, Token.Comment.Single, ' '),\n",
       " (103, Token.Comment.Single, 'B'),\n",
       " (104, Token.Comment.Single, '2'),\n",
       " (105, Token.Comment.Single, '0'),\n",
       " (106, Token.Comment.Single, '\"'),\n",
       " (107, Token.Comment.Single, ','),\n",
       " (108, Token.Comment.Single, ' '),\n",
       " (109, Token.Comment.Single, '\"'),\n",
       " (110, Token.Comment.Single, ','),\n",
       " (111, Token.Comment.Single, ' '),\n",
       " (112, Token.Comment.Single, 's'),\n",
       " (113, Token.Comment.Single, 'o'),\n",
       " (114, Token.Comment.Single, 'r'),\n",
       " (115, Token.Comment.Single, 't')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "list(_lex_tokens('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\", \"AG4B to AGB\", \"AG5B to AGC\")  //\"E20 to B20\", \", sort'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  //\"E20 to B20\", \", sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(remove_comments('*tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  //\"E20 to B20\", \", sort'), \n",
    "        '')\n",
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  /*\"E20 to B20\", \", sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  ')\n",
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  /*\"E20 to B20\", \"*/, sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  , sort')\n",
    "test_eq(remove_comments('tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")  ///\"E20 to B20\", \"*/ \\n , sort'),\n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\", \"E19 to B19\")   , sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    remove_comments(dedent(\"\"\"\\\n",
    "        disp ///\n",
    "        1\"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly ignores \"///\" when not preceded by a space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    remove_comments(dedent(\"\"\"\\\n",
    "        disp///\n",
    "        1\n",
    "        \"\"\")),\n",
    "    dedent(\"\"\"\\\n",
    "        disp///\n",
    "        1\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    remove_comments(dedent(\"\"\"\\\n",
    "        /*\n",
    "        blah\n",
    "        blah\n",
    "        */\n",
    "        list var\n",
    "        \"\"\")),\n",
    "    \"\"\"\\\n",
    "\n",
    "list var\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _end_block_followed_by_non_comment_block(code):\n",
    "    return (\n",
    "        code.rfind('*/') != -1\n",
    "        and not ends_in_comment_block(code[code.rfind('*/')+2:])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ends_in_comment_block(code):\n",
    "    last_token = list(_lex_tokens(code))[-1]\n",
    "    last_token_type = last_token[1]\n",
    "    return (\n",
    "        last_token_type == Comment.Multiline\n",
    "        and code.strip()[-2:] != \"*/\"\n",
    "        and not _end_block_followed_by_non_comment_block(code)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_in_comment_block('tab size /*if ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = 'tab size /*if */\\n*'\n",
    "code[code.rfind('*/')+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ends_in_comment_block('tab size /*if '), True)\n",
    "test_eq(ends_in_comment_block('tab size /*if */'), False)\n",
    "test_eq(ends_in_comment_block('tab size /*if */\\n*'), False)\n",
    "test_eq(ends_in_comment_block('tab size /*if */\\n//'), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _is_not_cr_delimiter(delimiter):\n",
    "    return delimiter != 'cr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "delimit_regex = re.compile(r'^[ \\t]*#delimit(.*$)', flags=re.MULTILINE)\n",
    "def _replace_delimiter(code, sc_delimiter=False):\n",
    "    # Recursively replace custom delimiter with newline\n",
    "\n",
    "    split = delimit_regex.split(code.strip(), maxsplit=1)\n",
    "\n",
    "    if len(split) == 3:\n",
    "        before = split[0]\n",
    "        after = _replace_delimiter(split[2], _is_not_cr_delimiter(split[1].strip()))\n",
    "    else:\n",
    "        before = code\n",
    "        after = ''\n",
    "\n",
    "    if sc_delimiter:\n",
    "        before_last_sc_pos = before.rfind(';')\n",
    "        if before_last_sc_pos < len(before.strip()) - 1:\n",
    "            before = before[:before_last_sc_pos+1]\n",
    "            if len(split) > 1:\n",
    "                after = _replace_delimiter(before[before_last_sc_pos+1:]+\" \".join(split[1:]), sc_delimiter=True)\n",
    "        before = before.replace('\\r', ' ').replace('\\n', ' ')\n",
    "        before = before.replace(';','\\n')\n",
    "\n",
    "    return before + after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disp 3\\n', ' cr', '\\ndisp 1\\ndisp 2\\n']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimit_regex.split(dedent(\"\"\"\\\n",
    "disp 3\n",
    "#delimit cr\n",
    "disp 1\n",
    "disp 2\n",
    "\"\"\"), maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/master/nbstata/code_utils.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _replace_delimiter\n",
       "\n",
       ">      _replace_delimiter (code, sc_delimiter=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hugetim/nbstata/blob/master/nbstata/code_utils.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### _replace_delimiter\n",
       "\n",
       ">      _replace_delimiter (code, sc_delimiter=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(_replace_delimiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following more-complicated regex would detect valid delimiters plus macros: \n",
    "```python\n",
    "delimit_regex = re.compile(r'#delimit( |\\t)+(;|cr|`.+\\'|\\$_.+|\\$.+)')\n",
    "```\n",
    "but that's unnecessary, since Stata's `#delimit x` interprets any `x` other than 'cr' as switching the delimiter to ';'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    _replace_delimiter(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2;list var3;\n",
    "        list\n",
    "        var4;\n",
    "        \"\"\")),\n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "         list var2\n",
    "        list var3\n",
    "         list var4\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    _replace_delimiter(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2;list var3;\n",
    "        list\n",
    "        var4\n",
    "        \"\"\")),\n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "         list var2\n",
    "        list var3\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_replace_delimiter(dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    #delimit;\n",
    "    disp \"hello\"; disp \"hello2\";\n",
    "    disp \n",
    "        \"hello2a\";\n",
    "    #delimit cr\n",
    "    disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    #delimit;\"\"\")), \n",
    "        dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    disp \"hello\"\n",
    "     disp \"hello2\"\n",
    "     disp      \"hello2a\"\n",
    "     disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_replace_delimiter(dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    #delimit;\n",
    "    disp \"hello\"; disp \"hello2\";\n",
    "    disp \n",
    "        \"hello2a\"\n",
    "    #delimit cr\n",
    "    disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    #delimit;\"\"\")).strip(), \n",
    "        dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    disp \"hello\"\n",
    "     disp \"hello2\"\n",
    "     \"\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_replace_delimiter(dedent(\"\"\"\\\n",
    "disp 3\n",
    "#delimit cr\n",
    "disp 1\n",
    "disp 2\n",
    "\"\"\"), sc_delimiter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _replace_tabs(code):\n",
    "    return code.replace(\"\\t\", \"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_replace_tabs(\"\\tsum\"), \"    sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def valid_single_line_code(code):\n",
    "    code = _replace_tabs(remove_comments(code))\n",
    "    if delimit_regex.match(code):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(valid_single_line_code('tab size if inlist(rt_from_to, \"A10TOU to B10\")  // E20'), \n",
    "        'tab size if inlist(rt_from_to, \"A10TOU to B10\")  ')\n",
    "test_eq(valid_single_line_code('#delimit ;'), \n",
    "        '')\n",
    "test_eq(valid_single_line_code('#delimit cr'), \n",
    "        '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ending_sc_delimiter(code, sc_delimiter=False):\n",
    "    code = remove_comments(code)\n",
    "    # Recursively determine ending delimiter\n",
    "    split = delimit_regex.split(code.strip(),maxsplit=1)\n",
    "    \n",
    "    if len(split) == 3:\n",
    "        before = split[0]\n",
    "    else:\n",
    "        before = code\n",
    "    if sc_delimiter:\n",
    "        before_last_sc_pos = before.rfind(';')\n",
    "        if before_last_sc_pos < len(before.strip()) - 1:\n",
    "            if len(split) > 1:\n",
    "                return ending_sc_delimiter(before[before_last_sc_pos+1:]+\" \".join(split[1:]), sc_delimiter=True)\n",
    "            \n",
    "    if len(split) == 3:\n",
    "        sc_delimiter = ending_sc_delimiter(split[2], _is_not_cr_delimiter(split[1].strip()))\n",
    "    elif len(split) == 2:\n",
    "        sc_delimiter = _is_not_cr_delimiter(split[1].strip())\n",
    "\n",
    "    return sc_delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2;list var3;\n",
    "        \"\"\")),\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        /*\n",
    "        #delimit;\n",
    "        */\n",
    "        disp 1\n",
    "        disp 2\"\"\")),\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        #delimit;\n",
    "        scalar\n",
    "        list x\"\"\")),\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    ending_sc_delimiter(dedent(\"\"\"\\\n",
    "        #delimit ;\"\"\")),\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ending_sc_delimiter(dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    #delimit;\n",
    "    disp \"hello\"; disp \"hello2\";\n",
    "    disp \n",
    "        \"hello2a\";\n",
    "    #delimit cr\n",
    "    disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    \"\"\")), \n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ending_sc_delimiter(dedent(\"\"\"\\\n",
    "    disp \"start\"\n",
    "    #delimit;\n",
    "    disp \"hello\"; disp \"hello2\";\n",
    "    disp \n",
    "        \"hello2a\"\n",
    "    #delimit cr\n",
    "    disp \"hello3\"\n",
    "    disp \"hello4\"\n",
    "    \"\"\")), \n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Detect Multiple whitespace\n",
    "multi_regex = re.compile(r'(?P<char>\\S) +')\n",
    "\n",
    "def standardize_code(code, sc_delimiter=False):\n",
    "    \"\"\"Remove comments spanning multiple lines and replace custom delimiters\"\"\"\n",
    "    code = remove_comments(code)\n",
    "    \n",
    "    # After removing multi-line comments, which could include \"#delimit;\"\n",
    "    code = _replace_delimiter(code, sc_delimiter) \n",
    "    \n",
    "    # Replace multiple interior whitespace with one\n",
    "    code = multi_regex.sub(r'\\g<char> ',code)\n",
    "    \n",
    "    # Delete blank lines and whitespace at end of lines\n",
    "    code_lines = code.splitlines()\n",
    "    std_lines = []\n",
    "    for code_line in code_lines:\n",
    "        cs = code_line.rstrip()\n",
    "        if cs:\n",
    "            std_lines.append(cs)\n",
    "    return '\\n'.join(std_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2; list var3;\n",
    "        list\n",
    "        var4;\n",
    "        \"\"\")), \n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "         list var2\n",
    "         list var3\n",
    "         list var4\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        list var1\n",
    "        #delimit;\n",
    "        list var2; list var3;\n",
    "        list\n",
    "        var4\n",
    "        \"\"\")), \n",
    "    dedent(\"\"\"\\\n",
    "        list var1\n",
    "         list var2\n",
    "         list var3\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        /*\n",
    "        blah\n",
    "        blah\n",
    "        */\n",
    "        list var\n",
    "        \"\"\")), \n",
    "    \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        /*\n",
    "        #delimit;\n",
    "        */\n",
    "        disp 1\n",
    "        disp 2\n",
    "        \"\"\")), \n",
    "    dedent(\"\"\"\\\n",
    "        disp 1\n",
    "        disp 2\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        disp ///\n",
    "        1\n",
    "        \"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        disp /// comment\n",
    "        1\n",
    "        \"\"\")),\n",
    "    \"disp 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    standardize_code(dedent(\"\"\"\\\n",
    "        list var\n",
    "        \"\"\")), \n",
    "    \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(standardize_code(\"list    var\"), \"list var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display \"displayed1\"\\ndisplay \"displayed3\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_code('''\\\n",
    "display \"displayed1\"\n",
    "/*\n",
    "display \"displayed2\"\n",
    "*/\n",
    "display \"displayed3\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display \"line continuation \" \"comment\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "standardize_code('''\\\n",
    "display \"line continuation \" /// commented out\n",
    "    \"comment\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(standardize_code('''\\\n",
    "try:\n",
    "    print(\"This works!\")'''), '''\\\n",
    "try:\n",
    "    print(\"This works!\")''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect version command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _startswith_stata_abbrev(string, full_command, shortest_abbrev):\n",
    "    for j in range(len(shortest_abbrev), len(full_command)+1):\n",
    "        if string.startswith(full_command[0:j] + ' '):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_startswith_stata_abbrev(\"q list var\", \"quietly\", \"q\"), True)\n",
    "test_eq(_startswith_stata_abbrev(\"qui list var\", \"quietly\", \"q\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _remove_prefixes(std_code_line):\n",
    "    std_code_line = std_code_line.lstrip()\n",
    "    if (_startswith_stata_abbrev(std_code_line, 'quietly', 'qui')\n",
    "        or std_code_line.startswith('capture ')\n",
    "        or _startswith_stata_abbrev(std_code_line, 'noisily', 'n')):\n",
    "        return _remove_prefixes(std_code_line.split(None, maxsplit=1)[1])\n",
    "    else:\n",
    "        return std_code_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_remove_prefixes(\"capture noisily program test_program\"), \"program test_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noisily', 'test_program']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "\"    noisily test_program\".split(None, maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_program'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "_remove_prefixes(\"    noisily test_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ending_code_version(code, sc_delimiter=False, code_version=None, stata_version='17.0'):\n",
    "    if 'version' not in code:\n",
    "        return code_version\n",
    "    std_code = standardize_code(code, sc_delimiter)\n",
    "    for std_code_line in reversed(std_code.splitlines()):\n",
    "        if 'version ' not in std_code_line:\n",
    "            continue\n",
    "        m = re.match(r'\\A\\s*version ([0-9]+(?:\\.[0-9][0-9]?)?)\\Z', _remove_prefixes(std_code_line))\n",
    "        if m:\n",
    "            _version = Decimal(m.group(1)).normalize()\n",
    "            if Decimal('1') <= _version <= Decimal(stata_version):\n",
    "                code_version = None if _version == Decimal(stata_version).normalize() else str(_version)\n",
    "                break\n",
    "    return code_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my trial and error, it seems that Stata's `version` command (as of version 17.0) accepts any number between 1 and your Stata version (inclusive) with up to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    ending_code_version(dedent(\"#delimit ;\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\" version 15\")),\n",
    "    \"15\")\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 15.0\")),\n",
    "    \"15\")\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 15.1\")),\n",
    "    \"15.1\")\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 15.141\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 23\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 0.7\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 17\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 17.0\")),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 17.0\"), stata_version=\"17.00\"),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 18.0\"), stata_version=\"18.00\"),\n",
    "    None)\n",
    "test_eq(\n",
    "    ending_code_version(dedent(\"version 18.0\"), stata_version=\"18.10\"),\n",
    "    \"18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for specific commands in std_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pre = (\n",
    "    r'(cap(t|tu|tur|ture)?'\n",
    "    r'|qui(e|et|etl|etly)?'\n",
    "    r'|n(o|oi|ois|oisi|oisil|oisily)?)')\n",
    "kwargs = {'flags': re.MULTILINE}\n",
    "local_def_in = re.compile(\n",
    "    r\"(^\\s*({0} )*(loc(a|al)?|tempname|tempvar|tempfile|gettoken|token(i|iz|ize)?|levelsof)\\s)|st_local\\(\".format(pre),\n",
    "    **kwargs,\n",
    ").search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(bool(local_def_in(\" sysuse auto\")), False)\n",
    "test_eq(bool(local_def_in(\" loc auto=1\")), True)\n",
    "test_eq(bool(local_def_in(\"qui n cap local auto=1\")), True)\n",
    "test_eq(bool(local_def_in(\"list local auto\")), False)\n",
    "test_eq(bool(local_def_in(\"tempfile file1\")), True)\n",
    "test_eq(bool(local_def_in(\" capture token file1\")), True)\n",
    "test_eq(bool(local_def_in(\"mata: st_local(test1, 2)\")), True)\n",
    "test_eq(bool(local_def_in(\"levelsof var1\")), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "preserve_restore_in = re.compile(\n",
    "    r\"(^({0} )*(preserve|restore)[,\\s]?\\.*?$)|(;({0} )*(preserve|restore)[,\\s]?\\.*?$)\".format(pre),\n",
    "    **kwargs,\n",
    ").search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(bool(preserve_restore_in(\"sysuse auto\")), False)\n",
    "test_eq(bool(preserve_restore_in(\"preserve\")), True)\n",
    "test_eq(bool(preserve_restore_in(\"preserve\\nkeep in 1\")), True)\n",
    "test_eq(bool(preserve_restore_in(\"restore,\")), True)\n",
    "test_eq(bool(preserve_restore_in(\"count\\nrestore\")), True)\n",
    "test_eq(bool(preserve_restore_in(\"gen restore=1\")), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate out Stata program code\n",
    "...because [such code](https://www.stata.com/manuals/pprogram.pdf) (as well as [python](https://www.stata.com/stata-news/news35-3/python-blogs/)/[mata](https://www.stata.com/manuals/m-1first.pdf) blocks) is unsuitable for `run_as_program`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_start_of_program_block(std_code_line):\n",
    "    cs = _remove_prefixes(std_code_line)\n",
    "    _starts_program = (_startswith_stata_abbrev(cs, 'program', 'pr')\n",
    "                       and not (cs.split()[1] in ['di', 'dir', 'drop', 'l', 'li', 'lis', 'list']))\n",
    "    return (_starts_program\n",
    "            or (cs in {'mata', 'mata:'})\n",
    "            or (cs in {'python', 'python:'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(is_start_of_program_block(\"capture noisily program test_program\"), True)\n",
    "test_eq(is_start_of_program_block(\" capture noisily list var\"), False)\n",
    "test_eq(is_start_of_program_block(\"pr l display1\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _prog_blocks(std_code_lines):\n",
    "    next_block_lines = []\n",
    "    in_program = False\n",
    "    for std_code_line in std_code_lines:         \n",
    "        if is_start_of_program_block(std_code_line):\n",
    "            if next_block_lines: # previous lines\n",
    "                yield _block(next_block_lines, is_prog=in_program)\n",
    "                next_block_lines = []\n",
    "            in_program = True\n",
    "        next_block_lines.append(std_code_line)\n",
    "        if std_code_line == 'end': # regardless of whether in_program\n",
    "            yield _block(next_block_lines, is_prog=True)\n",
    "            next_block_lines = []\n",
    "            in_program = False\n",
    "    if next_block_lines:\n",
    "        yield _block(next_block_lines, in_program)\n",
    "        \n",
    "\n",
    "def _block(block_lines, is_prog):\n",
    "    return {\"is_prog\": is_prog, \"std_code\": '\\n'.join(block_lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def break_out_prog_blocks(code, sc_delimiter=False):\n",
    "    std_code_lines = standardize_code(code, sc_delimiter).splitlines()\n",
    "    return list(_prog_blocks(std_code_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    break_out_prog_blocks(dedent('''\\\n",
    "        capture program drop ender\n",
    "        program define ender\n",
    "            disp \"ender output\"\n",
    "        end\n",
    "        capture program drop display2\n",
    "        program define display2\n",
    "            ender\n",
    "        end\n",
    "        display2\n",
    "        ''')),\n",
    "    [{'is_prog': False, 'std_code': 'capture program drop ender'},\n",
    "     {'is_prog': True,\n",
    "      'std_code': 'program define ender\\n    disp \"ender output\"\\nend'},\n",
    "     {'is_prog': False, 'std_code': 'capture program drop display2'},\n",
    "     {'is_prog': True, 'std_code': 'program define display2\\n    ender\\nend'},\n",
    "     {'is_prog': False, 'std_code': 'display2'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    break_out_prog_blocks(dedent('''\\\n",
    "        program define ender\n",
    "            disp \"ender output\"\n",
    "        ''')),\n",
    "    [{'is_prog': True,\n",
    "      'std_code': 'program define ender\\n    disp \"ender output\"'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_prog': False, 'std_code': 'display \"line continuation \" \"comment\"'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "break_out_prog_blocks('''\\\n",
    "display \"line continuation \" /// commented out\n",
    "    \"comment\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
